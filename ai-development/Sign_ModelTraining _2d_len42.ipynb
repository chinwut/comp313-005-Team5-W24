{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b41804e-097a-44ea-94b4-59c9c85c6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cab4904d-8182-4514-8894-6beb349c8640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('output_landmarks.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1fdf5b0-5eb7-4088-9114-a724774c9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_json(string):\n",
    "    try:\n",
    "        string = string.replace(\"'\", \"\\\"\")\n",
    "        string = string.replace(\"\\\"\\\"\\\"\", \"\\\"'\\\"\")\n",
    "        return json.loads(string)\n",
    "    except ValueError:\n",
    "        print(string)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da924280-b393-4c0c-8bde-0468b3d1bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Courses\\2024Winter\\COMP313\\Code\\output_landmarks.csv\", header=None, names=[\"index\", \"landmark\", \"target\"])\n",
    "df = pd.read_csv(r\"C:\\Users\\emrey\\Desktop\\Centennial\\FOURTH SEMESTER\\Software Development\\output_landmarks.csv\", header=None, names=[\"index\", \"landmark\", \"target\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d38afc77-5a38-419b-98c4-32e6008d90db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>landmark</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.3720352351665497, 0.5708810091018677, 5.6...</td>\n",
       "      <td>['d', 'c']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[[0.3651290535926819, 0.5668753981590271, 3.8...</td>\n",
       "      <td>['e', 'd']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.5721478462219238, 0.879878580570221, -1.6...</td>\n",
       "      <td>['a', 's', 'l', 'i', 'z', 'e', 'd']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[[0.3897995352745056, 0.5905594825744629, -1....</td>\n",
       "      <td>['a', 's', 'l', ' ', 'l', 'i', 't', 'e', 'r', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[[0.34600889682769775, 0.6220497488975525, 1....</td>\n",
       "      <td>['a', 'l', 'i', 'z', 'e', 'd']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[[], [], [[0.5789754390716553, 0.8081677556037...</td>\n",
       "      <td>['a', 's', 'l']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[[[0.5133020281791687, 0.6245256662368774, 1.7...</td>\n",
       "      <td>['a', 's', 'l']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[[[0.49991101026535034, 0.8499583005905151, -3...</td>\n",
       "      <td>['e', 'd']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[[[0.36749503016471863, 0.6053090691566467, 2....</td>\n",
       "      <td>['a', 's', 'l']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[[[0.63340163230896, 0.7506250143051147, -2.55...</td>\n",
       "      <td>['v', 'i', 'd', 'e', 'o']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           landmark  \\\n",
       "0      0  [[[0.3720352351665497, 0.5708810091018677, 5.6...   \n",
       "1      1  [[[0.3651290535926819, 0.5668753981590271, 3.8...   \n",
       "2      2  [[[0.5721478462219238, 0.879878580570221, -1.6...   \n",
       "3      3  [[[0.3897995352745056, 0.5905594825744629, -1....   \n",
       "4      4  [[[0.34600889682769775, 0.6220497488975525, 1....   \n",
       "5      5  [[], [], [[0.5789754390716553, 0.8081677556037...   \n",
       "6      6  [[[0.5133020281791687, 0.6245256662368774, 1.7...   \n",
       "7      7  [[[0.49991101026535034, 0.8499583005905151, -3...   \n",
       "8      8  [[[0.36749503016471863, 0.6053090691566467, 2....   \n",
       "9      9  [[[0.63340163230896, 0.7506250143051147, -2.55...   \n",
       "\n",
       "                                              target  \n",
       "0                                         ['d', 'c']  \n",
       "1                                         ['e', 'd']  \n",
       "2                ['a', 's', 'l', 'i', 'z', 'e', 'd']  \n",
       "3  ['a', 's', 'l', ' ', 'l', 'i', 't', 'e', 'r', ...  \n",
       "4                     ['a', 'l', 'i', 'z', 'e', 'd']  \n",
       "5                                    ['a', 's', 'l']  \n",
       "6                                    ['a', 's', 'l']  \n",
       "7                                         ['e', 'd']  \n",
       "8                                    ['a', 's', 'l']  \n",
       "9                          ['v', 'i', 'd', 'e', 'o']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a84bafc0-02d4-4c3d-9dc0-388657da0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['target'].apply(convert_to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b69129e-e8da-4598-8b9a-0b45fdd7c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['landmark'] = df['landmark'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17901122",
   "metadata": {},
   "source": [
    "# Display unique values on df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ddf941-c810-4241-92d3-b48c82bb608e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                         [c, d]\n",
      "1                         [e, d]\n",
      "2          [e, i, a, l, z, s, d]\n",
      "3    [e, t, i,  , a, l, u, s, r]\n",
      "4             [e, i, a, l, z, d]\n",
      "5                      [l, a, s]\n",
      "6                      [l, a, s]\n",
      "7                         [e, d]\n",
      "8                      [l, a, s]\n",
      "9                [e, i, o, d, v]\n",
      "Name: unique_target_per_row, dtype: object\n",
      "['e', 'j', '&', 'z', 'g', 'p', 'i', ' ', \"'\", '@', 'o', 's', 'd', 'r', 'v', 'x', 'n', 'q', 'a', 'm', 'f', '.', 'c', 'w', 'h', 't', 'y', 'b', 'l', 'u', 'k']\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "# Getting unique values for each row's target\n",
    "df['unique_target_per_row'] = df['target'].apply(lambda x: list(set(x)))\n",
    "\n",
    "# Getting unique values of 'target' among all rows\n",
    "unique_values_among_all_rows = list(set().union(*df['target']))\n",
    "\n",
    "# Displaying unique values per row\n",
    "print(df['unique_target_per_row'].head(10))\n",
    "\n",
    "# Displaying unique values among all rows\n",
    "print(unique_values_among_all_rows)\n",
    "print(len(unique_values_among_all_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce2e49",
   "metadata": {},
   "source": [
    "# Dropping the rows where labels contains non alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31878bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows containing non-alphabetical characters: 1114\n",
      "['e', 'j', 'z', 'g', 'p', 'i', 'o', 's', 'd', 'r', 'v', 'x', 'n', 'q', 'a', 'm', 'f', 'c', 'w', 'h', 't', 'y', 'b', 'l', 'u', 'k']\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame and 'target' is the column you're working with\n",
    "\n",
    "# Define a function to check for non-alphabetical characters in a list\n",
    "def contains_non_alpha(lst):\n",
    "    return any(not char.isalpha() for char in ''.join(lst))\n",
    "\n",
    "\n",
    "# Apply the function to the 'target' column to identify rows with non-alphabetical characters\n",
    "rows_with_non_alpha = df['target'].apply(contains_non_alpha)\n",
    "\n",
    "# Count rows containing non-alphabetical characters\n",
    "count_non_alpha_rows = rows_with_non_alpha.sum()\n",
    "\n",
    "# Drop these rows from the DataFrame\n",
    "# After dropping rows\n",
    "df = df[~rows_with_non_alpha].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(f\"Rows containing non-alphabetical characters: {count_non_alpha_rows}\")\n",
    "# df_clean will have rows removed that contained non-alphabetical characters in 'target'\n",
    "\n",
    "# Getting unique values of 'target' among all rows\n",
    "unique_values_among_all_rows2 = list(set().union(*df['target']))\n",
    "\n",
    "\n",
    "# Displaying unique values among all rows\n",
    "print(unique_values_among_all_rows2)\n",
    "print(len(unique_values_among_all_rows2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a8c22a",
   "metadata": {},
   "source": [
    "# investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ed080bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [[[0.37, 0.57, 0.0], [0.39, 0.55, -0.01], [0.4...\n",
      "1    [[[0.37, 0.57, 0.0], [0.39, 0.54, -0.02], [0.4...\n",
      "2    [[[0.57, 0.88, -0.0], [0.55, 0.84, -0.0], [0.5...\n",
      "3    [[[0.35, 0.62, 0.0], [0.37, 0.57, -0.0], [0.38...\n",
      "4    [[], [], [[0.58, 0.81, -0.0], [0.57, 0.75, 0.0...\n",
      "5    [[[0.51, 0.62, 0.0], [0.53, 0.58, 0.0], [0.56,...\n",
      "6    [[[0.5, 0.85, -0.0], [0.48, 0.78, 0.0], [0.47,...\n",
      "7    [[[0.37, 0.61, 0.0], [0.39, 0.57, 0.0], [0.41,...\n",
      "8    [[[0.63, 0.75, -0.0], [0.61, 0.69, -0.01], [0....\n",
      "9    [[[0.36, 0.63, -0.0], [0.39, 0.62, -0.01], [0....\n",
      "Name: rounded_landmark, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def round_nested_list(nested_list, decimals):\n",
    "    def round_item(item):\n",
    "        if isinstance(item, list):  # Check if the item is a list itself\n",
    "            return [round_item(sub_item) for sub_item in item]  # Recurse if item is a list\n",
    "        elif isinstance(item, (int, float)):  # Check if the item is numeric\n",
    "            return round(item, decimals)  # Round if item is a number\n",
    "        else:\n",
    "            return item  # Return the item unchanged if it's not a list or number\n",
    "    \n",
    "    return [round_item(item) for item in nested_list]\n",
    "\n",
    "# Assuming df['landmark'] contains nested lists that need rounding\n",
    "# Apply the rounding function\n",
    "df['rounded_landmark'] = df['landmark'].apply(lambda x: round_nested_list(x, 2))\n",
    "\n",
    "print(df['rounded_landmark'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92fb1c-c625-49b7-a198-4b65339093ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9ddf2bd-fe5c-4c32-a8c5-414a27428c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "# Slice to get the first 100 rows\n",
    "first_100_rows = df.iloc[:100]\n",
    "\n",
    "# Specify your desired output path\n",
    "output_path = r\"C:\\Users\\user\\Desktop\\Courses\\2024Winter\\COMP313\\Code\\first_100_output_landmarks.csv\"\n",
    "\n",
    "# Save to CSV without the index unless you need it\n",
    "first_100_rows.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4bed7a",
   "metadata": {},
   "source": [
    "# Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d52a04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['target']: \n",
      " 0                   [d, c]\n",
      "1                   [e, d]\n",
      "2    [a, s, l, i, z, e, d]\n",
      "3       [a, l, i, z, e, d]\n",
      "4                [a, s, l]\n",
      "Name: target, dtype: object\n",
      "Maximum dimensions found in df['landmark']: 125, 21, 3\n",
      "Maximum dimensions found in df['target']: 17, 0, 0\n"
     ]
    }
   ],
   "source": [
    "#print(json.dumps(rounded_landmark.iloc[0], indent=4))\n",
    "def find_dimensions(obj):\n",
    "    \"\"\"Find the dimensions of a nested list or a numpy array.\"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        # If the object is a numpy array, return its shape directly.\n",
    "        return obj.shape\n",
    "    elif isinstance(obj, list):\n",
    "        # If the object is a list, compute dimensions recursively as before.\n",
    "        if not obj:  # Base case: empty list\n",
    "            return []\n",
    "        return [len(obj)] + find_dimensions(obj[0])\n",
    "    else:\n",
    "        # If the object is neither a list nor a numpy array, return an empty list.\n",
    "        # Alternatively, you might handle other types or raise an error.\n",
    "        return []\n",
    "\n",
    "    \n",
    "print(\"df['target']: \\n\", df['target'].head())    \n",
    "    \n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Initialize variables to track the maximum dimensions\n",
    "max_dim1 = 0\n",
    "max_dim2 = 0\n",
    "max_dim3 = 0\n",
    "\n",
    "# Function to recursively find the maximum dimensions of a nested list\n",
    "def update_max_dims(landmark, level=0):\n",
    "    global max_dim1, max_dim2, max_dim3\n",
    "    # Check if the current element is a list (and not just a numerical value)\n",
    "    if isinstance(landmark, list):\n",
    "        # At the top level, update max_dim1 based on the number of elements (e.g., groups of coordinates)\n",
    "        if level == 0:\n",
    "            max_dim1 = max(max_dim1, len(landmark))\n",
    "        # At the first level of nesting, update max_dim2\n",
    "        elif level == 1:\n",
    "            max_dim2 = max(max_dim2, len(landmark))\n",
    "        # At the second level of nesting (actual coordinates), update max_dim3\n",
    "        elif level == 2:\n",
    "            max_dim3 = max(max_dim3, len(landmark))\n",
    "        \n",
    "        # Recursively process each element in the current list, incrementing the level\n",
    "        for sub_landmark in landmark:\n",
    "            update_max_dims(sub_landmark, level+1)\n",
    "\n",
    "# Iterate over the 'landmark' column and update maximum dimensions\n",
    "for landmark in df['landmark']:\n",
    "    update_max_dims(landmark)\n",
    "\n",
    "print(f\"Maximum dimensions found in df['landmark']: {max_dim1}, {max_dim2}, {max_dim3}\")\n",
    "max_dim1 = 0\n",
    "max_dim2 = 0\n",
    "max_dim3 = 0\n",
    "for target in df['target']:\n",
    "    update_max_dims(target)\n",
    "\n",
    "print(f\"Maximum dimensions found in df['target']: {max_dim1}, {max_dim2}, {max_dim3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2ff7d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 0 has 19 frames; First frame shape: (21, 3)\n",
      "Sequence 1 has 13 frames; First frame shape: (21, 3)\n",
      "Sequence 2 has 42 frames; First frame shape: (21, 3)\n",
      "Sequence 3 has 32 frames; First frame shape: (21, 3)\n",
      "Sequence 4 has 15 frames; First frame shape: (21, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def normalize_landmarks(landmarks_seq):\n",
    "    # This will hold the normalized sequences\n",
    "    normalized_seq = []\n",
    "    \n",
    "    for matrix in landmarks_seq:\n",
    "        # Ensure the matrix is not empty to avoid errors during scaling\n",
    "        if matrix:  # Checks if the matrix is not empty\n",
    "            matrix_np = np.array(matrix)\n",
    "            # Normalize the [21x3] matrix\n",
    "            # Note: scaler.fit_transform expects a 2D array, [samples, features]\n",
    "            # Reshape is used to ensure the matrix is 2D and to revert it back to original shape after scaling\n",
    "            scaled_matrix = scaler.fit_transform(matrix_np.reshape(-1, 3)).reshape(21, 3)\n",
    "            normalized_seq.append(scaled_matrix)\n",
    "        else:\n",
    "            # Handle empty matrices by appending an array of zeros or another placeholder\n",
    "            # This keeps the temporal structure consistent\n",
    "            normalized_seq.append(np.zeros((21, 3)))\n",
    "    \n",
    "    return normalized_seq\n",
    "\n",
    "# Apply the normalization function to each sequence in 'landmarks'\n",
    "df['normalized_landmarks'] = df['landmark'].apply(normalize_landmarks)\n",
    "\n",
    "\n",
    "# Display the structure of the first 5 elements in 'normalized_landmarks'\n",
    "for i in range(5):\n",
    "    # Access the ith element in 'normalized_landmarks'\n",
    "    landmarks_seq = df['normalized_landmarks'].iloc[i]\n",
    "    # Since landmarks_seq is a list of arrays, let's print out the number of frames\n",
    "    # and the shape of the first frame (if available) to understand its structure\n",
    "    num_frames = len(landmarks_seq)\n",
    "    first_frame_shape = landmarks_seq[0].shape if num_frames > 0 else \"No frames\"\n",
    "    print(f\"Sequence {i} has {num_frames} frames; First frame shape: {first_frame_shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e078c310",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c11298f",
   "metadata": {},
   "source": [
    "# Padding  df['normalized_landmarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41ae1ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 0 after padding has 125 frames.\n",
      "Sequence 0 has 125 frames; First frame shape: (21, 3)\n",
      "Sequence 1 after padding has 125 frames.\n",
      "Sequence 1 has 125 frames; First frame shape: (21, 3)\n",
      "Sequence 2 after padding has 125 frames.\n",
      "Sequence 2 has 125 frames; First frame shape: (21, 3)\n",
      "Sequence 3 after padding has 125 frames.\n",
      "Sequence 3 has 125 frames; First frame shape: (21, 3)\n",
      "Sequence 4 after padding has 125 frames.\n",
      "Sequence 4 has 125 frames; First frame shape: (21, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Pad the scaled landmark data\n",
    "max_frames = 125  # Target number of frames for each sequence\n",
    "\n",
    "def pad_sequence(sequence):\n",
    "    # Determine the number of frames to pad\n",
    "    num_frames_to_pad = max_frames - len(sequence)\n",
    "    \n",
    "    # Create frames of zeros to be appended\n",
    "    # Each frame is a (21, 3) array of zeros\n",
    "    padding_frames = [np.zeros((21, 3)) for _ in range(num_frames_to_pad)]\n",
    "    \n",
    "    # Append the padding frames to the sequence\n",
    "    padded_sequence = sequence + padding_frames\n",
    "    \n",
    "    return padded_sequence\n",
    "\n",
    "# Apply the padding function to each sequence in 'normalized_landmarks'\n",
    "df['padded_normalized_landmarks'] = df['normalized_landmarks'].apply(pad_sequence)\n",
    "\n",
    "\n",
    "\n",
    "# Verify the padding for the first 5 sequences\n",
    "for i in range(5):\n",
    "    num_frames = len(df['padded_normalized_landmarks'].iloc[i])\n",
    "    print(f\"Sequence {i} after padding has {num_frames} frames.\")\n",
    "    first_frame_shape = landmarks_seq[0].shape if num_frames > 0 else \"No frames\"\n",
    "    print(f\"Sequence {i} has {num_frames} frames; First frame shape: {first_frame_shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba8b2a8",
   "metadata": {},
   "source": [
    "# Padding df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb7e9f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 0 in 'padded_target' has 17 elements.\n",
      "Sequence 1 in 'padded_target' has 17 elements.\n",
      "Sequence 2 in 'padded_target' has 17 elements.\n",
      "Sequence 3 in 'padded_target' has 17 elements.\n",
      "Sequence 4 in 'padded_target' has 17 elements.\n"
     ]
    }
   ],
   "source": [
    "max_length_target = 17  # The maximum length of target sequences\n",
    "\n",
    "def pad_target_sequence(target_seq):\n",
    "    # Calculate the number of elements to pad\n",
    "    num_elements_to_pad = max_length_target - len(target_seq)\n",
    "    \n",
    "    # Create the padding elements\n",
    "    padding_elements = [0] * num_elements_to_pad  # Use 0 or another appropriate padding token\n",
    "    \n",
    "    # Append the padding elements to the target sequence\n",
    "    padded_target_seq = target_seq + padding_elements\n",
    "    \n",
    "    return padded_target_seq\n",
    "\n",
    "# Apply the padding function to each target sequence in 'target'\n",
    "df['padded_target'] = df['target'].apply(pad_target_sequence)\n",
    "\n",
    "# Verify the first 5 sequences in 'padded_target'\n",
    "for i in range(5):\n",
    "    seq_length = len(df['padded_target'].iloc[i])\n",
    "    print(f\"Sequence {i} in 'padded_target' has {seq_length} elements.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266dc55",
   "metadata": {},
   "source": [
    "# Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b434ea86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to integer code mapping: {'0': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Flatten the list of all sequences to get a list of all labels\n",
    "# Assuming df['padded_target'] contains sequences of labels\n",
    "all_labels = [label for sequence in df['padded_target'] for label in sequence]\n",
    "\n",
    "# Initialize the LabelEncoder and fit it with the flattened list of all labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "def encode_sequence(sequence):\n",
    "    # Transform each element in the sequence using the fitted LabelEncoder\n",
    "    return [label_encoder.transform([item])[0] for item in sequence]\n",
    "\n",
    "# Apply the encoding function to each sequence in 'padded_target'\n",
    "df['encoded_target'] = df['padded_target'].apply(encode_sequence)\n",
    "\n",
    "\n",
    "# Display the unique labels and their corresponding integer codes\n",
    "labels_and_codes = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label to integer code mapping:\", labels_and_codes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c650738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the label encoder to a file\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad82a7",
   "metadata": {},
   "source": [
    "# Preprocessed features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baa88829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [[[-1.2153970288004756, 2.3753629941416357, 2....\n",
      "1    [[[0.2901805728306801, 2.12861539170463, 2.667...\n",
      "2    [[[2.6813927528272097, 0.3813247752700488, 2.0...\n",
      "3    [[[-1.3134348894070909, 2.2045729014403244, 2....\n",
      "4    [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...\n",
      "5    [[[-2.4358860944922798, 0.5291534544608159, 1....\n",
      "6    [[[0.6172452529867535, 2.6189231677172247, 1.5...\n",
      "7    [[[-2.3207745744526025, 0.7424863477272686, 2....\n",
      "8    [[[0.2045866255829034, 1.8983832688894848, 2.5...\n",
      "9    [[[-0.5809574688840651, 0.45024894346511807, 2...\n",
      "Name: padded_normalized_landmarks, dtype: object\n",
      "0    [4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "1    [5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "2    [1, 19, 12, 9, 26, 5, 4, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "3    [1, 12, 9, 26, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0...\n",
      "4    [1, 19, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...\n",
      "5    [1, 19, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...\n",
      "6    [5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "7    [1, 19, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...\n",
      "8    [22, 9, 4, 5, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...\n",
      "9    [1, 19, 12, 9, 26, 5, 4, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "Name: encoded_target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['padded_normalized_landmarks'].head(10))\n",
    "print(df['encoded_target'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2dda93-3146-4418-acd7-9c1be868bb08",
   "metadata": {},
   "source": [
    "# dropping z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "752f97bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original first sequence length: 125\n",
      "Original frame shape: (21, 3)\n",
      "Reshaped first sequence length: 125\n",
      "Reshaped frame shape: 63\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example DataFrame setup for context\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame({'padded_normalized_landmarks': [np.random.rand(125, 21, 2) for _ in range(5)]})\n",
    "\n",
    "# Process each sequence to reshape the frames\n",
    "# Assuming df['padded_normalized_landmarks'] contains your sequences\n",
    "df['reshaped_landmarks'] = df['padded_normalized_landmarks'].apply(\n",
    "    lambda seq: np.concatenate(seq, axis=1).reshape(125, -1).tolist()\n",
    ")\n",
    "# Now, df['reshaped_landmarks'] contains sequences with shape (125, 42)\n",
    "\n",
    "# Verifying the \"shape\" change for the first sequence by checking the length\n",
    "original_first_seq_length = len(df['padded_normalized_landmarks'].iloc[0])\n",
    "original_frame_shape = df['padded_normalized_landmarks'].iloc[0][0].shape\n",
    "\n",
    "reshaped_first_seq_length = len(df['reshaped_landmarks'].iloc[0])\n",
    "reshaped_frame_shape = len(df['reshaped_landmarks'].iloc[0][0])\n",
    "\n",
    "print(f\"Original first sequence length: {original_first_seq_length}\")\n",
    "print(f\"Original frame shape: {original_frame_shape}\")\n",
    "print(f\"Reshaped first sequence length: {reshaped_first_seq_length}\")\n",
    "print(f\"Reshaped frame shape: {reshaped_frame_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a1bda03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['reshaped_landmarks'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cbe004c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>landmark</th>\n",
       "      <th>target</th>\n",
       "      <th>unique_target_per_row</th>\n",
       "      <th>rounded_landmark</th>\n",
       "      <th>normalized_landmarks</th>\n",
       "      <th>padded_normalized_landmarks</th>\n",
       "      <th>padded_target</th>\n",
       "      <th>encoded_target</th>\n",
       "      <th>reshaped_landmarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.3720352351665497, 0.5708810091018677, 5.6...</td>\n",
       "      <td>[d, c]</td>\n",
       "      <td>[c, d]</td>\n",
       "      <td>[[[0.37, 0.57, 0.0], [0.39, 0.55, -0.01], [0.4...</td>\n",
       "      <td>[[[-1.2153970288004756, 2.3753629941416357, 2....</td>\n",
       "      <td>[[[-1.2153970288004756, 2.3753629941416357, 2....</td>\n",
       "      <td>[d, c, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[-1.2153970288004756, 2.3753629941416357, 2.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[[0.3651290535926819, 0.5668753981590271, 3.8...</td>\n",
       "      <td>[e, d]</td>\n",
       "      <td>[d, e]</td>\n",
       "      <td>[[[0.37, 0.57, 0.0], [0.39, 0.54, -0.02], [0.4...</td>\n",
       "      <td>[[[0.2901805728306801, 2.12861539170463, 2.667...</td>\n",
       "      <td>[[[0.2901805728306801, 2.12861539170463, 2.667...</td>\n",
       "      <td>[e, d, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0.2901805728306801, 2.12861539170463, 2.6670...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.5721478462219238, 0.879878580570221, -1.6...</td>\n",
       "      <td>[a, s, l, i, z, e, d]</td>\n",
       "      <td>[l, i, a, e, s, z, d]</td>\n",
       "      <td>[[[0.57, 0.88, -0.0], [0.55, 0.84, -0.0], [0.5...</td>\n",
       "      <td>[[[2.6813927528272097, 0.3813247752700488, 2.0...</td>\n",
       "      <td>[[[2.6813927528272097, 0.3813247752700488, 2.0...</td>\n",
       "      <td>[a, s, l, i, z, e, d, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 19, 12, 9, 26, 5, 4, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[2.6813927528272097, 0.3813247752700488, 2.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[[[0.34600889682769775, 0.6220497488975525, 1....</td>\n",
       "      <td>[a, l, i, z, e, d]</td>\n",
       "      <td>[l, i, a, e, z, d]</td>\n",
       "      <td>[[[0.35, 0.62, 0.0], [0.37, 0.57, -0.0], [0.38...</td>\n",
       "      <td>[[[-1.3134348894070909, 2.2045729014403244, 2....</td>\n",
       "      <td>[[[-1.3134348894070909, 2.2045729014403244, 2....</td>\n",
       "      <td>[a, l, i, z, e, d, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 12, 9, 26, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[-1.3134348894070909, 2.2045729014403244, 2.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[[], [], [[0.5789754390716553, 0.8081677556037...</td>\n",
       "      <td>[a, s, l]</td>\n",
       "      <td>[s, l, a]</td>\n",
       "      <td>[[], [], [[0.58, 0.81, -0.0], [0.57, 0.75, 0.0...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>[a, s, l, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 19, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.000440961209...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           landmark  \\\n",
       "0      0  [[[0.3720352351665497, 0.5708810091018677, 5.6...   \n",
       "1      1  [[[0.3651290535926819, 0.5668753981590271, 3.8...   \n",
       "2      2  [[[0.5721478462219238, 0.879878580570221, -1.6...   \n",
       "3      4  [[[0.34600889682769775, 0.6220497488975525, 1....   \n",
       "4      5  [[], [], [[0.5789754390716553, 0.8081677556037...   \n",
       "\n",
       "                  target  unique_target_per_row  \\\n",
       "0                 [d, c]                 [c, d]   \n",
       "1                 [e, d]                 [d, e]   \n",
       "2  [a, s, l, i, z, e, d]  [l, i, a, e, s, z, d]   \n",
       "3     [a, l, i, z, e, d]     [l, i, a, e, z, d]   \n",
       "4              [a, s, l]              [s, l, a]   \n",
       "\n",
       "                                    rounded_landmark  \\\n",
       "0  [[[0.37, 0.57, 0.0], [0.39, 0.55, -0.01], [0.4...   \n",
       "1  [[[0.37, 0.57, 0.0], [0.39, 0.54, -0.02], [0.4...   \n",
       "2  [[[0.57, 0.88, -0.0], [0.55, 0.84, -0.0], [0.5...   \n",
       "3  [[[0.35, 0.62, 0.0], [0.37, 0.57, -0.0], [0.38...   \n",
       "4  [[], [], [[0.58, 0.81, -0.0], [0.57, 0.75, 0.0...   \n",
       "\n",
       "                                normalized_landmarks  \\\n",
       "0  [[[-1.2153970288004756, 2.3753629941416357, 2....   \n",
       "1  [[[0.2901805728306801, 2.12861539170463, 2.667...   \n",
       "2  [[[2.6813927528272097, 0.3813247752700488, 2.0...   \n",
       "3  [[[-1.3134348894070909, 2.2045729014403244, 2....   \n",
       "4  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...   \n",
       "\n",
       "                         padded_normalized_landmarks  \\\n",
       "0  [[[-1.2153970288004756, 2.3753629941416357, 2....   \n",
       "1  [[[0.2901805728306801, 2.12861539170463, 2.667...   \n",
       "2  [[[2.6813927528272097, 0.3813247752700488, 2.0...   \n",
       "3  [[[-1.3134348894070909, 2.2045729014403244, 2....   \n",
       "4  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...   \n",
       "\n",
       "                                       padded_target  \\\n",
       "0  [d, c, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [e, d, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [a, s, l, i, z, e, d, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [a, l, i, z, e, d, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [a, s, l, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                      encoded_target  \\\n",
       "0  [4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 19, 12, 9, 26, 5, 4, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [1, 12, 9, 26, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "4  [1, 19, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                                  reshaped_landmarks  \n",
       "0  [[-1.2153970288004756, 2.3753629941416357, 2.3...  \n",
       "1  [[0.2901805728306801, 2.12861539170463, 2.6670...  \n",
       "2  [[2.6813927528272097, 0.3813247752700488, 2.09...  \n",
       "3  [[-1.3134348894070909, 2.2045729014403244, 2.0...  \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.000440961209...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a332018-95ae-45cc-8337-89e0c381c1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original first sequence length: 125\n",
      "Original first frame shape: (21, 3)\n",
      "Modified first sequence length: 125\n",
      "Modified first frame shape: (21, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example DataFrame setup for context\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame({'padded_normalized_landmarks': [np.random.rand(125, 21, 3) for _ in range(5)]})\n",
    "\n",
    "# Process each sequence to remove the third column\n",
    "# Assuming df['padded_normalized_landmarks'] contains your sequences\n",
    "df['padded_normalized_landmarks_21x2'] = df['padded_normalized_landmarks'].apply(\n",
    "    lambda seq: np.array(seq)[:, :, :2].tolist()\n",
    ")\n",
    "# Now, df['padded_normalized_landmarks_21x2'] contains sequences with shape (125, 21, 2)\n",
    "\n",
    "# Verifying the \"shape\" change for the first sequence by checking the lengths\n",
    "original_first_seq_length = len(df['padded_normalized_landmarks'].iloc[0])\n",
    "original_first_frame_shape = (len(df['padded_normalized_landmarks'].iloc[0][0]), len(df['padded_normalized_landmarks'].iloc[0][0][0]))\n",
    "\n",
    "modified_first_seq_length = len(df['padded_normalized_landmarks_21x2'].iloc[0])\n",
    "modified_first_frame_shape = (len(df['padded_normalized_landmarks_21x2'].iloc[0][0]), len(df['padded_normalized_landmarks_21x2'].iloc[0][0][0]))\n",
    "\n",
    "print(f\"Original first sequence length: {original_first_seq_length}\")\n",
    "print(f\"Original first frame shape: {original_first_frame_shape}\")\n",
    "print(f\"Modified first sequence length: {modified_first_seq_length}\")\n",
    "print(f\"Modified first frame shape: {modified_first_frame_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22e38370",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['padded_normalized_landmarks_42']=df['padded_normalized_landmarks_21x2'].apply(lambda x : np.array(x))\n",
    "df['padded_normalized_landmarks_42']=df['padded_normalized_landmarks_42'].apply(lambda x : x.reshape(125,42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0b7b9",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "508d1b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assume df['padded_normalized_landmarks'] and df['encoded_target'] are already prepared\n",
    "X = np.stack(df['padded_normalized_landmarks_42'].values)\n",
    "y = np.array([to_categorical(sequence, num_classes=27) for sequence in df['encoded_target']])\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5858aa2",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a818789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, Reshape, Flatten\n",
    "# import numpy as np\n",
    "\n",
    "# num_encoder_tokens = 63  # 21 landmarks * 3 coordinates\n",
    "# num_decoder_tokens = 27  # Including 0-26 (26 letters + 'blank')\n",
    "# latent_dim = 256  # Latent dimensionality of the encoding space\n",
    "# # Adjusting configuration to accept the 3D frame shape directly\n",
    "# num_encoder_tokens = 21 * 3  # Keeping this for clarity, though not directly used below\n",
    "\n",
    "# # Encoder\n",
    "# encoder_inputs = Input(shape=(125, 21, 3))  # Adjusted to match the input shape\n",
    "\n",
    "# # Flatten the spatial dimensions of the frame for the LSTM\n",
    "# encoder_inputs_flat = TimeDistributed(Flatten())(encoder_inputs)\n",
    "\n",
    "# encoder = LSTM(latent_dim, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs_flat)\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "# # Decoder setup remains the same\n",
    "# decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "# decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# # Define the adjusted model\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a36adbe",
   "metadata": {},
   "source": [
    "# LSTM with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b44db615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer  [(None, 125, 42)]            0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " encoder_inputs_flat (TimeD  (None, 125, 42)              0         ['encoder_inputs[0][0]']      \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer  [(None, None, 27)]           0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)         [(None, 125, 256),           306176    ['encoder_inputs_flat[0][0]'] \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)         [(None, None, 256),          290816    ['decoder_inputs[0][0]',      \n",
      "                              (None, 256),                           'encoder_lstm[0][1]',        \n",
      "                              (None, 256)]                           'encoder_lstm[0][2]']        \n",
      "                                                                                                  \n",
      " attention_layer (Attention  (None, None, 256)            0         ['decoder_lstm[0][0]',        \n",
      " )                                                                   'encoder_lstm[0][0]']        \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)  (None, None, 512)            0         ['decoder_lstm[0][0]',        \n",
      "                                                                     'attention_layer[0][0]']     \n",
      "                                                                                                  \n",
      " decoder_dense (Dense)       (None, None, 27)             13851     ['concat_layer[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 610843 (2.33 MB)\n",
      "Trainable params: 610843 (2.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, Flatten, Concatenate, Attention\n",
    "import numpy as np\n",
    "\n",
    "num_encoder_tokens = 42  # 21 landmarks * 2 coordinates (Not directly used, but for clarity)\n",
    "num_decoder_tokens = 27  # Including 0-26 (26 letters + 'blank')\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(125, 42), name='encoder_inputs')\n",
    "encoder_inputs_flat = TimeDistributed(Flatten(), name='encoder_inputs_flat')(encoder_inputs)\n",
    "\n",
    "# Using return_sequences=True to get all hidden states for attention\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, return_sequences=True, name='encoder_lstm')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs_flat)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder_inputs')\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# Attention Layer\n",
    "attention_layer = Attention(name='attention_layer')\n",
    "attention_result = attention_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "# Concatenating the attention output and the decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention_result])\n",
    "\n",
    "# Dense layer\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0238fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_train, y_val are one-hot encoded and already split\n",
    "# Shift target sequences one timestep for decoder input, introducing start token\n",
    "decoder_input_train = np.zeros_like(y_train)\n",
    "decoder_input_val = np.zeros_like(y_val)\n",
    "decoder_input_train[:, 1:, :] = y_train[:, :-1, :]\n",
    "decoder_input_val[:, 1:, :] = y_val[:, :-1, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c1bed41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "59/59 [==============================] - 53s 746ms/step - loss: 1.0857 - accuracy: 0.7484 - val_loss: 1.0145 - val_accuracy: 0.7516\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 40s 682ms/step - loss: 0.8963 - accuracy: 0.7672 - val_loss: 0.9252 - val_accuracy: 0.7690\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 42s 718ms/step - loss: 0.8488 - accuracy: 0.7705 - val_loss: 0.8570 - val_accuracy: 0.7722\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 42s 712ms/step - loss: 0.8051 - accuracy: 0.7760 - val_loss: 0.8391 - val_accuracy: 0.7683\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 42s 718ms/step - loss: 0.7716 - accuracy: 0.7802 - val_loss: 0.9349 - val_accuracy: 0.7649\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 42s 710ms/step - loss: 0.7415 - accuracy: 0.7887 - val_loss: 0.8336 - val_accuracy: 0.7621\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 41s 700ms/step - loss: 0.7108 - accuracy: 0.7968 - val_loss: 0.7233 - val_accuracy: 0.7880\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 40s 673ms/step - loss: 0.6837 - accuracy: 0.8040 - val_loss: 0.8049 - val_accuracy: 0.7798\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 40s 672ms/step - loss: 0.6595 - accuracy: 0.8100 - val_loss: 0.7130 - val_accuracy: 0.7940\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 40s 674ms/step - loss: 0.6349 - accuracy: 0.8185 - val_loss: 0.7282 - val_accuracy: 0.7961\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 40s 676ms/step - loss: 0.6143 - accuracy: 0.8236 - val_loss: 0.6848 - val_accuracy: 0.8027\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 40s 673ms/step - loss: 0.5914 - accuracy: 0.8315 - val_loss: 0.6636 - val_accuracy: 0.8130\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 41s 698ms/step - loss: 0.5734 - accuracy: 0.8348 - val_loss: 0.6919 - val_accuracy: 0.8084\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 43s 725ms/step - loss: 0.5548 - accuracy: 0.8410 - val_loss: 0.7366 - val_accuracy: 0.7979\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 42s 716ms/step - loss: 0.5409 - accuracy: 0.8451 - val_loss: 0.6352 - val_accuracy: 0.8162\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 42s 717ms/step - loss: 0.5208 - accuracy: 0.8494 - val_loss: 0.6271 - val_accuracy: 0.8228\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 29s 491ms/step - loss: 0.5041 - accuracy: 0.8552 - val_loss: 0.6869 - val_accuracy: 0.8060\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 21s 351ms/step - loss: 0.4927 - accuracy: 0.8584 - val_loss: 0.5907 - val_accuracy: 0.8315\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 21s 359ms/step - loss: 0.4754 - accuracy: 0.8612 - val_loss: 0.6125 - val_accuracy: 0.8339\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 21s 358ms/step - loss: 0.4634 - accuracy: 0.8660 - val_loss: 0.6161 - val_accuracy: 0.8253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21905be1790>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit([X_train, decoder_input_train], y_train, batch_size=64, epochs=20, validation_data=([X_val, decoder_input_val], y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dcbede",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d97a734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emrey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model_sign_2d_dim42.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f0599",
   "metadata": {},
   "source": [
    "# Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "501435bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 2s 47ms/step - loss: 0.6101 - accuracy: 0.8266\n",
      "Test Loss: 0.610126793384552\n",
      "Test Accuracy: 0.8266178965568542\n"
     ]
    }
   ],
   "source": [
    "# Preparing decoder_input_test similar to decoder_input_train and decoder_input_val\n",
    "decoder_input_test = np.zeros_like(y_test)\n",
    "decoder_input_test[:, 1:, :] = y_test[:, :-1, :]\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate([X_test, decoder_input_test], y_test, verbose=1)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b03886fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 27)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a7144fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 835ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Assuming num_decoder_tokens is defined as the number of tokens in your decoder vocabulary\n",
    "num_decoder_tokens = 27  # Including 0-26 (26 letters + 'blank')\n",
    "\n",
    "# Reshape the data point to match the input shape of the decoder model\n",
    "decoder_input_data = np.zeros((1, 1, num_decoder_tokens))  # Initialize decoder input data\n",
    "\n",
    "# Set the first token (start token) to 1\n",
    "decoder_input_data[0, 0, 0] = 1  # Assuming the first token represents the start token\n",
    "\n",
    "# Make predictions using the model\n",
    "decoder_output_data = model.predict(([dummy_array, decoder_input_data]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f346cf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19]], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = np.argmax(decoder_output_data, axis=-1)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e57f07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_test[:,1:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e6bf46",
   "metadata": {},
   "source": [
    "# Test Predicton presentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45b87e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.07063874e-10, 1.24656010e-08, 6.39067082e-07, 1.31045226e-07,\n",
       "        8.38511646e-01, 1.40038566e-04, 2.42143142e-06, 7.50711251e-07,\n",
       "        1.31595769e-07, 1.23739490e-08, 2.77366695e-07, 1.65909587e-04,\n",
       "        6.11476366e-07, 8.51442110e-06, 3.04915716e-07, 1.49868652e-06,\n",
       "        3.97147305e-05, 6.88448472e-06, 1.65901525e-04, 2.51985085e-03,\n",
       "        1.44903504e-04, 1.57305002e-01, 8.78686842e-04, 8.68660118e-06,\n",
       "        2.25113208e-08, 5.21320730e-11, 9.74789073e-05],\n",
       "       [7.65537678e-09, 1.15289209e-08, 1.10208564e-09, 1.85441495e-05,\n",
       "        5.81177846e-06, 9.49103415e-01, 4.35545289e-08, 3.79766227e-08,\n",
       "        1.37311398e-10, 3.26950862e-06, 1.27080668e-07, 1.57599239e-10,\n",
       "        1.71655247e-05, 5.82714543e-10, 3.57860859e-11, 5.82137181e-05,\n",
       "        5.69968028e-09, 8.47796997e-08, 4.49338449e-06, 5.07864617e-02,\n",
       "        1.71086083e-06, 1.50928159e-07, 4.52895428e-08, 1.10998872e-08,\n",
       "        8.90828602e-08, 7.88709364e-09, 2.78862643e-07],\n",
       "       [3.42050754e-03, 5.11551752e-06, 2.29888695e-08, 9.90855575e-01,\n",
       "        7.60068870e-05, 4.73113684e-03, 1.00236466e-05, 1.38419491e-05,\n",
       "        9.48615630e-11, 4.55758027e-07, 1.29014688e-06, 1.70532442e-08,\n",
       "        2.66584568e-04, 5.76377746e-09, 1.17772788e-11, 1.50984430e-04,\n",
       "        2.07327382e-08, 9.07794444e-08, 4.25271018e-08, 1.47551382e-05,\n",
       "        4.45537909e-04, 1.01644639e-08, 1.49180277e-08, 2.52305244e-06,\n",
       "        1.78643018e-06, 1.83622842e-06, 1.92232051e-06],\n",
       "       [9.99952674e-01, 1.87058977e-05, 1.36406567e-10, 2.14332103e-05,\n",
       "        1.53040148e-07, 2.70807334e-07, 1.55501638e-07, 1.97868374e-07,\n",
       "        2.57835286e-09, 1.46547293e-07, 8.02761324e-09, 4.35928165e-08,\n",
       "        3.72362774e-06, 9.03581743e-09, 4.67055908e-12, 1.32537264e-06,\n",
       "        3.62583470e-11, 1.39819733e-07, 1.41037404e-08, 1.44048562e-09,\n",
       "        5.70290695e-07, 8.66332506e-10, 1.83270329e-10, 7.17473583e-08,\n",
       "        4.06035916e-09, 4.66511324e-07, 2.64535815e-09],\n",
       "       [1.00000000e+00, 1.77965323e-10, 5.66087069e-15, 2.25839729e-11,\n",
       "        4.03354162e-13, 9.59211660e-13, 2.94482266e-13, 2.88710757e-11,\n",
       "        3.00916349e-14, 3.46626096e-11, 4.20094488e-13, 7.68062236e-14,\n",
       "        3.66721653e-11, 4.87530101e-13, 4.55401705e-16, 3.98340111e-10,\n",
       "        1.07983985e-15, 6.97241006e-12, 9.98120748e-13, 2.42490930e-14,\n",
       "        4.94035195e-12, 6.23347619e-13, 4.80015742e-16, 6.10927671e-12,\n",
       "        3.89570713e-14, 8.40964191e-12, 8.79875379e-15],\n",
       "       [1.00000000e+00, 2.78542068e-11, 5.57034118e-16, 9.30574888e-12,\n",
       "        1.32573396e-13, 1.44133688e-13, 1.50085209e-14, 1.97942843e-11,\n",
       "        3.12133208e-15, 3.75005270e-11, 9.61157898e-14, 9.40384660e-16,\n",
       "        1.83373217e-12, 3.53694802e-14, 2.81498615e-16, 1.16016710e-10,\n",
       "        9.16615963e-16, 7.45541649e-13, 9.19711789e-13, 7.45727129e-15,\n",
       "        2.91997416e-12, 4.78383846e-14, 3.79020212e-17, 1.51817957e-13,\n",
       "        3.98681129e-15, 4.50684629e-12, 1.02486699e-15],\n",
       "       [1.00000000e+00, 3.18024947e-11, 1.48671885e-16, 5.21659105e-11,\n",
       "        7.21064037e-14, 2.72793994e-13, 9.52708608e-15, 5.40785750e-11,\n",
       "        2.62979907e-15, 3.98195608e-11, 7.62746799e-14, 6.87559354e-16,\n",
       "        6.50423021e-13, 1.17969175e-14, 9.52555465e-16, 1.79069204e-10,\n",
       "        9.10076233e-16, 4.84008341e-13, 6.00738383e-12, 4.36268301e-15,\n",
       "        1.10298983e-11, 2.86444960e-14, 2.54220528e-17, 3.33338263e-14,\n",
       "        3.96333789e-15, 1.91127409e-11, 2.44015877e-15],\n",
       "       [1.00000000e+00, 1.02604071e-11, 2.62417458e-17, 3.36421932e-11,\n",
       "        1.92041021e-14, 2.23534326e-13, 2.27845531e-15, 3.42864313e-11,\n",
       "        8.67199161e-16, 5.42136301e-12, 2.69929088e-14, 2.66046220e-16,\n",
       "        2.11562172e-13, 2.51607198e-15, 5.01352925e-16, 8.33904681e-11,\n",
       "        2.40371989e-16, 1.17542938e-13, 4.26444166e-12, 1.04423979e-15,\n",
       "        7.43000887e-12, 4.64231653e-15, 5.12889368e-18, 8.43129481e-15,\n",
       "        1.88539285e-15, 1.45796118e-11, 2.45710282e-15],\n",
       "       [1.00000000e+00, 2.70114248e-12, 3.42209727e-18, 3.49249254e-12,\n",
       "        1.83051104e-15, 3.25907277e-14, 2.97465874e-16, 6.57143350e-12,\n",
       "        1.87933860e-16, 6.29121538e-13, 7.33032308e-15, 2.60661535e-17,\n",
       "        3.86032894e-14, 4.10938061e-16, 6.67952447e-17, 1.18556961e-11,\n",
       "        3.49754992e-17, 1.49273853e-14, 7.50581129e-13, 3.03748556e-16,\n",
       "        1.02472382e-12, 4.02036274e-16, 4.44456447e-19, 1.39709678e-15,\n",
       "        3.21425101e-16, 2.72276928e-12, 4.75001095e-16],\n",
       "       [1.00000000e+00, 1.57090844e-12, 1.01934832e-18, 6.54916984e-13,\n",
       "        3.03207911e-16, 4.59962268e-15, 7.29731060e-17, 1.46671304e-12,\n",
       "        6.91984824e-17, 1.61199003e-13, 3.10963752e-15, 4.64041499e-18,\n",
       "        1.16933754e-14, 1.34618549e-16, 1.40214608e-17, 3.42546434e-12,\n",
       "        1.03588713e-17, 3.74976573e-15, 1.98024946e-13, 1.21641382e-16,\n",
       "        2.73591235e-13, 8.37333560e-17, 8.35644350e-20, 3.89869122e-16,\n",
       "        9.15266811e-17, 6.06717855e-13, 1.01123538e-16],\n",
       "       [1.00000000e+00, 1.83740132e-12, 7.39595007e-19, 4.10282404e-13,\n",
       "        1.53794925e-16, 1.52776400e-15, 4.24908552e-17, 7.93564379e-13,\n",
       "        4.82600661e-17, 1.03357427e-13, 2.40673041e-15, 2.83074813e-18,\n",
       "        7.11102963e-15, 1.00543102e-16, 9.94190860e-18, 2.62591381e-12,\n",
       "        7.97147008e-18, 2.37793827e-15, 1.15268567e-13, 7.50675472e-17,\n",
       "        2.12617182e-13, 5.87134255e-17, 4.62104966e-20, 2.35469310e-16,\n",
       "        5.73734657e-17, 3.22132620e-13, 5.55949082e-17],\n",
       "       [1.00000000e+00, 2.76848618e-12, 7.18088104e-19, 4.66737597e-13,\n",
       "        1.45179713e-16, 9.98357183e-16, 3.90719060e-17, 7.40117982e-13,\n",
       "        4.46784072e-17, 1.04096765e-13, 2.49025230e-15, 3.26977569e-18,\n",
       "        6.07283363e-15, 1.01339789e-16, 1.13246452e-17, 2.85354119e-12,\n",
       "        9.69657510e-18, 2.42574545e-15, 9.46186150e-14, 5.98193924e-17,\n",
       "        2.78438188e-13, 7.09327625e-17, 4.36635170e-20, 2.19253089e-16,\n",
       "        5.09071103e-17, 2.94940396e-13, 5.22411243e-17],\n",
       "       [1.00000000e+00, 4.06514015e-12, 7.30423745e-19, 5.95915298e-13,\n",
       "        1.63966970e-16, 8.86052261e-16, 4.17750065e-17, 7.78490120e-13,\n",
       "        4.54535449e-17, 1.17531053e-13, 2.75534354e-15, 4.24978060e-18,\n",
       "        6.02681603e-15, 1.06871729e-16, 1.30172942e-17, 3.13470127e-12,\n",
       "        1.30129754e-17, 2.79495695e-15, 8.65930659e-14, 5.37208545e-17,\n",
       "        3.74810372e-13, 9.37887223e-17, 4.88346431e-20, 2.37312506e-16,\n",
       "        5.04195038e-17, 3.18499919e-13, 5.79687710e-17],\n",
       "       [1.00000000e+00, 5.43460459e-12, 7.74477110e-19, 7.47536527e-13,\n",
       "        1.95223585e-16, 8.67076764e-16, 4.77967226e-17, 8.10910963e-13,\n",
       "        4.89126455e-17, 1.31738804e-13, 3.08720428e-15, 5.48922886e-18,\n",
       "        6.57426909e-15, 1.16412013e-16, 1.48837503e-17, 3.35824250e-12,\n",
       "        1.74330911e-17, 3.29758863e-15, 8.60738686e-14, 5.23476519e-17,\n",
       "        4.70683659e-13, 1.20310019e-16, 5.83756674e-20, 2.73902530e-16,\n",
       "        5.35179470e-17, 3.51763432e-13, 6.81051283e-17],\n",
       "       [1.00000000e+00, 6.80447972e-12, 8.62907991e-19, 9.25144835e-13,\n",
       "        2.38687982e-16, 8.81329470e-16, 5.73555192e-17, 8.48900757e-13,\n",
       "        5.56789498e-17, 1.44873439e-13, 3.52145033e-15, 7.16837697e-18,\n",
       "        7.63889294e-15, 1.33301664e-16, 1.78307863e-17, 3.63062033e-12,\n",
       "        2.28997243e-17, 3.95154761e-15, 9.19941207e-14, 5.46614184e-17,\n",
       "        5.82003250e-13, 1.50736872e-16, 7.25845882e-20, 3.29180561e-16,\n",
       "        5.99175953e-17, 3.91968657e-13, 8.25163682e-17],\n",
       "       [1.00000000e+00, 8.24571054e-12, 9.95184510e-19, 1.13862066e-12,\n",
       "        2.92074245e-16, 9.27063479e-16, 6.99492977e-17, 8.99940007e-13,\n",
       "        6.59463324e-17, 1.57299737e-13, 4.08202541e-15, 9.44500135e-18,\n",
       "        9.16941710e-15, 1.57565836e-16, 2.19531667e-17, 4.01597158e-12,\n",
       "        2.90583818e-17, 4.74823800e-15, 1.01849776e-13, 5.96621487e-17,\n",
       "        7.17115766e-13, 1.86597295e-16, 9.12267706e-20, 4.01541210e-16,\n",
       "        6.89949959e-17, 4.40468598e-13, 1.00615232e-16],\n",
       "       [1.00000000e+00, 9.72880283e-12, 1.16018667e-18, 1.37075095e-12,\n",
       "        3.48434123e-16, 9.95239149e-16, 8.35951639e-17, 9.49361032e-13,\n",
       "        7.84947484e-17, 1.67487172e-13, 4.72707489e-15, 1.22158885e-17,\n",
       "        1.10498430e-14, 1.86835192e-16, 2.66778817e-17, 4.49469932e-12,\n",
       "        3.50440129e-17, 5.59908302e-15, 1.12336464e-13, 6.60863510e-17,\n",
       "        8.52948517e-13, 2.27019494e-16, 1.12612213e-19, 4.84450965e-16,\n",
       "        7.95634525e-17, 4.90579365e-13, 1.20100457e-16]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8857961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 3s 48ms/step\n",
      "True Sequence      1: [ 4 14  3]\n",
      "Predicted Sequence 1: [4 5 3]\n",
      "\n",
      "True Sequence      2: [ 3 15 14 19 20  5 12 12  1 20  9 15 14]\n",
      "Predicted Sequence 2: [23 15 13 16 20  9  9  9  9  9  0 15 14]\n",
      "\n",
      "True Sequence      3: [ 9 12 15 23]\n",
      "Predicted Sequence 3: [ 2 12 15 23]\n",
      "\n",
      "True Sequence      4: [14 15 21 14 19]\n",
      "Predicted Sequence 4: [14  1 21 19 19]\n",
      "\n",
      "True Sequence      5: [ 1  2 19 12]\n",
      "Predicted Sequence 5: [20 20 19 20]\n",
      "\n",
      "True Sequence      6: [12  9 14 11]\n",
      "Predicted Sequence 6: [23  3  3  4]\n",
      "\n",
      "True Sequence      7: [13 15 14 20  1  7  5 19]\n",
      "Predicted Sequence 7: [ 1  1 14 20  0  0 19 19 20]\n",
      "\n",
      "True Sequence      8: [6 2]\n",
      "Predicted Sequence 8: [20  4  5]\n",
      "\n",
      "True Sequence      9: [ 3  1 21 19  5]\n",
      "Predicted Sequence 9: [ 3  1  8 14]\n",
      "\n",
      "True Sequence      10: [16 18  1 14 11]\n",
      "Predicted Sequence 10: [16 18  1 14  4]\n",
      "\n",
      "True Sequence      11: [ 1 19 12]\n",
      "Predicted Sequence 11: [16 19 20]\n",
      "\n",
      "True Sequence      12: [12  9  5 12 19]\n",
      "Predicted Sequence 12: [ 4  9 13 20 20]\n",
      "\n",
      "True Sequence      13: [15 23 14]\n",
      "Predicted Sequence 13: [ 2 18 21 19]\n",
      "\n",
      "True Sequence      14: [16  5 18 19 15 14  9  6  9  3  1 20  9 15 14]\n",
      "Predicted Sequence 14: [22 18 18  9  9  9  9  6  9 20 20  0  9 15 14]\n",
      "\n",
      "True Sequence      15: [4 2 3]\n",
      "Predicted Sequence 15: [2 2 3]\n",
      "\n",
      "True Sequence      16: [11 15  1 12  1]\n",
      "Predicted Sequence 16: [ 4  1  1 12  1]\n",
      "\n",
      "True Sequence      17: [14  1  4]\n",
      "Predicted Sequence 17: [20  1  4]\n",
      "\n",
      "True Sequence      18: [19  5 20]\n",
      "Predicted Sequence 18: [ 1  5 20]\n",
      "\n",
      "True Sequence      19: [2 3 5 4]\n",
      "Predicted Sequence 19: [3 9 4 4]\n",
      "\n",
      "True Sequence      20: [21 19  5  6 21 12]\n",
      "Predicted Sequence 20: [ 9 19]\n",
      "\n",
      "True Sequence      21: [5 4]\n",
      "Predicted Sequence 21: [5 4]\n",
      "\n",
      "True Sequence      22: [ 8  9 19 20 15 18  9  3]\n",
      "Predicted Sequence 22: [16  5 20 20 12 18  0  5]\n",
      "\n",
      "True Sequence      23: [19 15]\n",
      "Predicted Sequence 23: [19 15]\n",
      "\n",
      "True Sequence      24: [ 4  1 20  1]\n",
      "Predicted Sequence 24: [ 4  1 20  1]\n",
      "\n",
      "True Sequence      25: [ 2  9 18  4]\n",
      "Predicted Sequence 25: [22  8 14]\n",
      "\n",
      "True Sequence      26: [ 4  5 20  1  9 12]\n",
      "Predicted Sequence 26: [ 1  5  1  1  9 12]\n",
      "\n",
      "True Sequence      27: [ 6  1 14 19]\n",
      "Predicted Sequence 27: [ 6  1 14 19]\n",
      "\n",
      "True Sequence      28: [ 1  4 22  5 18 19  9 20  9  5 19]\n",
      "Predicted Sequence 28: [ 3  3  9  9 19 19  0 15 19 15 19]\n",
      "\n",
      "True Sequence      29: [15 19  3  1 18]\n",
      "Predicted Sequence 29: [15  3  0  4 22  5]\n",
      "\n",
      "True Sequence      30: [3 8 5 9 6]\n",
      "Predicted Sequence 30: [3 8 5 9 6]\n",
      "\n",
      "True Sequence      31: [ 4 15]\n",
      "Predicted Sequence 31: [ 4 15]\n",
      "\n",
      "True Sequence      32: [14  1  4]\n",
      "Predicted Sequence 32: [14  1  4]\n",
      "\n",
      "True Sequence      33: [ 5 22 14]\n",
      "Predicted Sequence 33: [21 21 20]\n",
      "\n",
      "True Sequence      34: [ 1 14  1 12 15  7  9  3  1 12]\n",
      "Predicted Sequence 34: [15 12 19 19 19 14 19]\n",
      "\n",
      "True Sequence      35: [ 8 15 15  4]\n",
      "Predicted Sequence 35: [14  5 16 12]\n",
      "\n",
      "True Sequence      36: [ 1 19 12]\n",
      "Predicted Sequence 36: [ 1 12 12]\n",
      "\n",
      "True Sequence      37: [22 15 20  5 19]\n",
      "Predicted Sequence 37: [ 4  4  4  0 18 12]\n",
      "\n",
      "True Sequence      38: [ 8 21 14  7 18 25]\n",
      "Predicted Sequence 38: [ 8  5 23  0  5]\n",
      "\n",
      "True Sequence      39: [ 1  3 20]\n",
      "Predicted Sequence 39: [ 1  3 20]\n",
      "\n",
      "True Sequence      40: [ 4  3 15]\n",
      "Predicted Sequence 40: [4 5]\n",
      "\n",
      "True Sequence      41: [ 3 15 14  4  9 15 14]\n",
      "Predicted Sequence 41: [ 5  5  4  4 15 15 14]\n",
      "\n",
      "True Sequence      42: [ 9 20  8 15 20 18 15 12]\n",
      "Predicted Sequence 42: [ 8 14 14  5 18 20  5 14  5]\n",
      "\n",
      "True Sequence      43: [9 6]\n",
      "Predicted Sequence 43: [1 6]\n",
      "\n",
      "True Sequence      44: [ 3 15  4  5]\n",
      "Predicted Sequence 44: [4 4 4]\n",
      "\n",
      "True Sequence      45: [ 3 15  6 20]\n",
      "Predicted Sequence 45: [19 15 14 19]\n",
      "\n",
      "True Sequence      46: [13 15 21  5 13 14 20 19]\n",
      "Predicted Sequence 46: [ 9 21 21  6 18  0  5  5]\n",
      "\n",
      "True Sequence      47: [ 1 19 12]\n",
      "Predicted Sequence 47: [ 2 19]\n",
      "\n",
      "True Sequence      48: [15 18]\n",
      "Predicted Sequence 48: [ 5 18]\n",
      "\n",
      "True Sequence      49: [4 5 3]\n",
      "Predicted Sequence 49: [4 5]\n",
      "\n",
      "True Sequence      50: [18 15  2 20]\n",
      "Predicted Sequence 50: [19  5  4  5  5]\n",
      "\n",
      "True Sequence      51: [23 15 23]\n",
      "Predicted Sequence 51: [23  5  5]\n",
      "\n",
      "True Sequence      52: [ 7 18  1 19 19 18 15 15 20 19]\n",
      "Predicted Sequence 52: [ 7 18  1 16 20 20  5 16 16 18]\n",
      "\n",
      "True Sequence      53: [20  1 24]\n",
      "Predicted Sequence 53: [20  1  4]\n",
      "\n",
      "True Sequence      54: [ 3 19 21  2  9  1]\n",
      "Predicted Sequence 54: [ 3  5  0  9  9 14 14]\n",
      "\n",
      "True Sequence      55: [ 5  6 20  9 22  5 12 25]\n",
      "Predicted Sequence 55: [ 9  4  4  9 18  9 18  9]\n",
      "\n",
      "True Sequence      56: [3 9]\n",
      "Predicted Sequence 56: [3 9]\n",
      "\n",
      "True Sequence      57: [18  5 20  9 19]\n",
      "Predicted Sequence 57: [18  5 15  9]\n",
      "\n",
      "True Sequence      58: [23  5  2 19  9 20  5]\n",
      "Predicted Sequence 58: [23  5  2 19  9 20 20]\n",
      "\n",
      "True Sequence      59: [20  1  3 20  9 12  5 19]\n",
      "Predicted Sequence 59: [20  1 24 20  5  5 19 19]\n",
      "\n",
      "True Sequence      60: [19  8  1 18  9  1]\n",
      "Predicted Sequence 60: [19  8 15 18  1  1]\n",
      "\n",
      "True Sequence      61: [18  5 17 21  5 19 20]\n",
      "Predicted Sequence 61: [18  5  6 21  5 19 20]\n",
      "\n",
      "True Sequence      62: [ 7 12  1 13 15 18]\n",
      "Predicted Sequence 62: [ 4 18  9  0  0 14]\n",
      "\n",
      "True Sequence      63: [20 13 16]\n",
      "Predicted Sequence 63: [20 13 16]\n",
      "\n",
      "True Sequence      64: [9 6]\n",
      "Predicted Sequence 64: [10  6]\n",
      "\n",
      "True Sequence      65: [ 1 13  2  1 19 19  4 15 18]\n",
      "Predicted Sequence 65: [ 1 13  3 19 19 15 15 18 18]\n",
      "\n",
      "True Sequence      66: [ 5  9 12]\n",
      "Predicted Sequence 66: [ 5  9 12  1]\n",
      "\n",
      "True Sequence      67: [ 4  9 19  1  2  9 12  9 20 25]\n",
      "Predicted Sequence 67: [16  9  1 18 18  9 18  9 20 25]\n",
      "\n",
      "True Sequence      68: [18]\n",
      "Predicted Sequence 68: [18 21]\n",
      "\n",
      "True Sequence      69: [14  1  4]\n",
      "Predicted Sequence 69: [1 1 9 9]\n",
      "\n",
      "True Sequence      70: [23  5 12 12]\n",
      "Predicted Sequence 70: [15  1 12 12]\n",
      "\n",
      "True Sequence      71: [15 18]\n",
      "Predicted Sequence 71: [5 3]\n",
      "\n",
      "True Sequence      72: [ 3 15]\n",
      "Predicted Sequence 72: [3 3]\n",
      "\n",
      "True Sequence      73: [ 1 12 12]\n",
      "Predicted Sequence 73: [ 1 12 12]\n",
      "\n",
      "True Sequence      74: [ 8 19]\n",
      "Predicted Sequence 74: [8 5]\n",
      "\n",
      "True Sequence      75: [20 18  1 22  5 19 20 25]\n",
      "Predicted Sequence 75: [20 18  1 22  5 19 20 25]\n",
      "\n",
      "True Sequence      76: [ 8  9 12 12]\n",
      "Predicted Sequence 76: [ 8 21 13 25 25]\n",
      "\n",
      "True Sequence      77: [15 18]\n",
      "Predicted Sequence 77: [ 4 18]\n",
      "\n",
      "True Sequence      78: [19  1 12 11]\n",
      "Predicted Sequence 78: [19  1]\n",
      "\n",
      "True Sequence      79: [13 19 19  4]\n",
      "Predicted Sequence 79: [13  5  4  4]\n",
      "\n",
      "True Sequence      80: [12  9 22  9 14  7]\n",
      "Predicted Sequence 80: [12  9  1  5  1  1  1]\n",
      "\n",
      "True Sequence      81: [20 16]\n",
      "Predicted Sequence 81: [20  5]\n",
      "\n",
      "True Sequence      82: [20 22]\n",
      "Predicted Sequence 82: [20  1  5]\n",
      "\n",
      "True Sequence      83: [ 5 20  6]\n",
      "Predicted Sequence 83: [23 21]\n",
      "\n",
      "True Sequence      84: [ 9 16  6]\n",
      "Predicted Sequence 84: [15  3]\n",
      "\n",
      "True Sequence      85: [ 1 20 18 25]\n",
      "Predicted Sequence 85: [20 12  5  5]\n",
      "\n",
      "True Sequence      86: [19  8  1 18  9  1]\n",
      "Predicted Sequence 86: [19  8  1 18  9 19]\n",
      "\n",
      "True Sequence      87: [15 11]\n",
      "Predicted Sequence 87: [14 11]\n",
      "\n",
      "True Sequence      88: [ 1 12 12]\n",
      "Predicted Sequence 88: [ 1 23  5]\n",
      "\n",
      "True Sequence      89: [13  2 21 11]\n",
      "Predicted Sequence 89: [13  5  5  5]\n",
      "\n",
      "True Sequence      90: [ 2 21 20]\n",
      "Predicted Sequence 90: [ 2 21 20]\n",
      "\n",
      "True Sequence      91: [ 1 18 20]\n",
      "Predicted Sequence 91: [20 19 19]\n",
      "\n",
      "True Sequence      92: [21 14]\n",
      "Predicted Sequence 92: [21 14]\n",
      "\n",
      "True Sequence      93: [14 15 14  4  8 19]\n",
      "Predicted Sequence 93: [ 7 14 14]\n",
      "\n",
      "True Sequence      94: [ 8 15 20  3  1]\n",
      "Predicted Sequence 94: [ 8  1 20  3  1]\n",
      "\n",
      "True Sequence      95: [ 9 18 15 14]\n",
      "Predicted Sequence 95: [16 14 14 14]\n",
      "\n",
      "True Sequence      96: [ 3  9 20  6  1]\n",
      "Predicted Sequence 96: [ 3 15  1  1  9]\n",
      "\n",
      "True Sequence      97: [9 6]\n",
      "Predicted Sequence 97: [4 3]\n",
      "\n",
      "True Sequence      98: [19 12  9 20]\n",
      "Predicted Sequence 98: [ 1 12  9  4  5]\n",
      "\n",
      "True Sequence      99: [20 18  9  1 12 19]\n",
      "Predicted Sequence 99: [20  1  1 14 20 19]\n",
      "\n",
      "True Sequence      100: [ 4  1 20  1]\n",
      "Predicted Sequence 100: [ 4  1 20  1]\n",
      "\n",
      "True Sequence      101: [ 3  1 12 12]\n",
      "Predicted Sequence 101: [19 19 12]\n",
      "\n",
      "True Sequence      102: [ 6 12  1]\n",
      "Predicted Sequence 102: [ 6 12  1]\n",
      "\n",
      "True Sequence      103: [16  1 20 20  5 18 14]\n",
      "Predicted Sequence 103: [16  1 20  5  5 14 14]\n",
      "\n",
      "True Sequence      104: [16  1  7  5]\n",
      "Predicted Sequence 104: [ 1  1 20  5 18]\n",
      "\n",
      "True Sequence      105: [20 15 14]\n",
      "Predicted Sequence 105: [20  3  3  5]\n",
      "\n",
      "True Sequence      106: [ 3 15  7 14 20  9  1 14]\n",
      "Predicted Sequence 106: [ 3 12 14 13  0  5 14 14]\n",
      "\n",
      "True Sequence      107: [ 6  1  3  2 11]\n",
      "Predicted Sequence 107: [6 1 2 8]\n",
      "\n",
      "True Sequence      108: [15  6]\n",
      "Predicted Sequence 108: [15  6]\n",
      "\n",
      "True Sequence      109: [8 4]\n",
      "Predicted Sequence 109: [16 12 12]\n",
      "\n",
      "True Sequence      110: [9 6]\n",
      "Predicted Sequence 110: [15  6]\n",
      "\n",
      "True Sequence      111: [19 16  1 13]\n",
      "Predicted Sequence 111: [19  8  1 18]\n",
      "\n",
      "True Sequence      112: [21 14  4  5 18 19  3 15 18  5]\n",
      "Predicted Sequence 112: [20 14  4  0 24 20 20  5 20 20 20]\n",
      "\n",
      "True Sequence      113: [9 6]\n",
      "Predicted Sequence 113: [9 6]\n",
      "\n",
      "True Sequence      114: [25  1  8 15 15 15]\n",
      "Predicted Sequence 114: [10  1  8  5]\n",
      "\n",
      "True Sequence      115: [ 9 20]\n",
      "Predicted Sequence 115: [19 20]\n",
      "\n",
      "True Sequence      116: [19 16  1  3  5]\n",
      "Predicted Sequence 116: [16 12  0  3]\n",
      "\n",
      "True Sequence      117: [ 4 15 13]\n",
      "Predicted Sequence 117: [4 5]\n",
      "\n",
      "True Sequence      118: [20  1 24]\n",
      "Predicted Sequence 118: [20  5 24]\n",
      "\n",
      "True Sequence      119: [ 2  5  1  3 11]\n",
      "Predicted Sequence 119: [ 5 25 12 12]\n",
      "\n",
      "True Sequence      120: [20  8  5 18  5]\n",
      "Predicted Sequence 120: [23 23  5 23]\n",
      "\n",
      "True Sequence      121: [19 20  3 12]\n",
      "Predicted Sequence 121: [19 12 12 12]\n",
      "\n",
      "True Sequence      122: [ 6  5 13  9 20]\n",
      "Predicted Sequence 122: [ 9  5 13]\n",
      "\n",
      "True Sequence      123: [ 8 15 18  9 26 15 14 20  1 12]\n",
      "Predicted Sequence 123: [ 3 15 18  9 22  5 14  0  5  9  9]\n",
      "\n",
      "True Sequence      124: [15 18]\n",
      "Predicted Sequence 124: [ 2 11]\n",
      "\n",
      "True Sequence      125: [ 1 23 20  9]\n",
      "Predicted Sequence 125: [ 1 19 12  0 24]\n",
      "\n",
      "True Sequence      126: [5 4]\n",
      "Predicted Sequence 126: [4 4 1]\n",
      "\n",
      "True Sequence      127: [ 1 19 12]\n",
      "Predicted Sequence 127: [ 1 19 12]\n",
      "\n",
      "True Sequence      128: [16  1 18  5 14 20 19]\n",
      "Predicted Sequence 128: [ 3  3  3 25  0  0 25]\n",
      "\n",
      "True Sequence      129: [21 19]\n",
      "Predicted Sequence 129: [21 19]\n",
      "\n",
      "True Sequence      130: [15 18]\n",
      "Predicted Sequence 130: [12 18]\n",
      "\n",
      "True Sequence      131: [19  5 13  9 14  1 18 19]\n",
      "Predicted Sequence 131: [ 5  5  9  9 14 15 18 19]\n",
      "\n",
      "True Sequence      132: [16 13]\n",
      "Predicted Sequence 132: [13  8  1]\n",
      "\n",
      "True Sequence      133: [ 8 21 18 20]\n",
      "Predicted Sequence 133: [ 8 21 18 20]\n",
      "\n",
      "True Sequence      134: [15 19 16 21 19 16]\n",
      "Predicted Sequence 134: [19 11 16]\n",
      "\n",
      "True Sequence      135: [ 1 18 20  9  3]\n",
      "Predicted Sequence 135: [3 3 9 9 3]\n",
      "\n",
      "True Sequence      136: [19  5  1]\n",
      "Predicted Sequence 136: [22 20 22 22]\n",
      "\n",
      "True Sequence      137: [21 14]\n",
      "Predicted Sequence 137: [21 14]\n",
      "\n",
      "True Sequence      138: [14  4  5  3]\n",
      "Predicted Sequence 138: [ 1  1  9 12]\n",
      "\n",
      "True Sequence      139: [ 4 22 20 22]\n",
      "Predicted Sequence 139: [ 4 22 20 22]\n",
      "\n",
      "True Sequence      140: [23  6  4]\n",
      "Predicted Sequence 140: [23  5  5]\n",
      "\n",
      "True Sequence      141: [15 11]\n",
      "Predicted Sequence 141: [15 11]\n",
      "\n",
      "True Sequence      142: [ 7 22 14]\n",
      "Predicted Sequence 142: [12 22 14]\n",
      "\n",
      "True Sequence      143: [23 15 23]\n",
      "Predicted Sequence 143: [23 22 22]\n",
      "\n",
      "True Sequence      144: [23  5  2  9 20  5 19]\n",
      "Predicted Sequence 144: [23  5  2  9  5  5 19]\n",
      "\n",
      "True Sequence      145: [12 22]\n",
      "Predicted Sequence 145: [12 18 25]\n",
      "\n",
      "True Sequence      146: [ 8  1 14  4 12  9 14  7]\n",
      "Predicted Sequence 146: [ 1  1 14  4 12  9 14  7]\n",
      "\n",
      "True Sequence      147: [23 23  6]\n",
      "Predicted Sequence 147: [23  6  6]\n",
      "\n",
      "True Sequence      148: [ 1 14  9 13  1 20 15 18 19]\n",
      "Predicted Sequence 148: [ 1 19  9  4  4 19 19  0 19]\n",
      "\n",
      "True Sequence      149: [19 11  9 16]\n",
      "Predicted Sequence 149: [19 11  0  1]\n",
      "\n",
      "True Sequence      150: [15 11]\n",
      "Predicted Sequence 150: [ 1 11]\n",
      "\n",
      "True Sequence      151: [13  1 19  8]\n",
      "Predicted Sequence 151: [ 8 21 14 11]\n",
      "\n",
      "True Sequence      152: [12  1 20  5 24]\n",
      "Predicted Sequence 152: [19 19 25  5]\n",
      "\n",
      "True Sequence      153: [12  1 14  5]\n",
      "Predicted Sequence 153: [12  1  5  5]\n",
      "\n",
      "True Sequence      154: [16  5 20]\n",
      "Predicted Sequence 154: [16 16 18  5]\n",
      "\n",
      "True Sequence      155: [12  9 14 11]\n",
      "Predicted Sequence 155: [12  1 11 11]\n",
      "\n",
      "True Sequence      156: [22  9 21 14  3  5 14  5 14]\n",
      "Predicted Sequence 156: [22  9 18 18  0  5 14  5]\n",
      "\n",
      "True Sequence      157: [14  5 21 18 15]\n",
      "Predicted Sequence 157: [ 1  1  0 13 15]\n",
      "\n",
      "True Sequence      158: [14 26 19 12]\n",
      "Predicted Sequence 158: [14  3  7 12  5]\n",
      "\n",
      "True Sequence      159: [ 1 18  9 26 15 14  1]\n",
      "Predicted Sequence 159: [ 3  3 12 12  1 14  0  3]\n",
      "\n",
      "True Sequence      160: [ 3  5 12 12 19]\n",
      "Predicted Sequence 160: [19 15]\n",
      "\n",
      "True Sequence      161: [15  6]\n",
      "Predicted Sequence 161: [9 6]\n",
      "\n",
      "True Sequence      162: [23 23  6]\n",
      "Predicted Sequence 162: [20 23  6]\n",
      "\n",
      "True Sequence      163: [20  8  5]\n",
      "Predicted Sequence 163: [20 15]\n",
      "\n",
      "True Sequence      164: [ 7 14  4]\n",
      "Predicted Sequence 164: [ 4 18 11]\n",
      "\n",
      "True Sequence      165: [20 18  1 20]\n",
      "Predicted Sequence 165: [20  1  1 16 16]\n",
      "\n",
      "True Sequence      166: [10  9 13]\n",
      "Predicted Sequence 166: [ 7 13 13]\n",
      "\n",
      "True Sequence      167: [ 9  4  5 15 16  8 15 14  5 19]\n",
      "Predicted Sequence 167: [ 9  4  5 19 14 18 18 14 19 19]\n",
      "\n",
      "True Sequence      168: [ 4 14  3]\n",
      "Predicted Sequence 168: [4 5 3]\n",
      "\n",
      "True Sequence      169: [25 12 20]\n",
      "Predicted Sequence 169: [25 19  5 19]\n",
      "\n",
      "True Sequence      170: [23  1]\n",
      "Predicted Sequence 170: [18  5 19]\n",
      "\n",
      "True Sequence      171: [ 9 24 12]\n",
      "Predicted Sequence 171: [19 19]\n",
      "\n",
      "True Sequence      172: [ 6  1 14 19]\n",
      "Predicted Sequence 172: [ 6  1 14 19]\n",
      "\n",
      "True Sequence      173: [20 15 15 12]\n",
      "Predicted Sequence 173: [20 15 12 12]\n",
      "\n",
      "True Sequence      174: [14  1  4]\n",
      "Predicted Sequence 174: [ 4  1 22]\n",
      "\n",
      "True Sequence      175: [6 2]\n",
      "Predicted Sequence 175: [6 2]\n",
      "\n",
      "True Sequence      176: [ 3  8 15 18  4]\n",
      "Predicted Sequence 176: [ 3  8  5 18  5  5]\n",
      "\n",
      "True Sequence      177: [ 6  3 15 18]\n",
      "Predicted Sequence 177: [15 12  5]\n",
      "\n",
      "True Sequence      178: [14  1  4]\n",
      "Predicted Sequence 178: [21  1 20]\n",
      "\n",
      "True Sequence      179: [11 18 20]\n",
      "Predicted Sequence 179: [ 8  5 20]\n",
      "\n",
      "True Sequence      180: [ 7 15  6 21 14  4 13  5]\n",
      "Predicted Sequence 180: [ 7 15  3 18 13 13 13]\n",
      "\n",
      "True Sequence      181: [13  1  3  2  5 20  8]\n",
      "Predicted Sequence 181: [19 21  3  9  9 18  9]\n",
      "\n",
      "True Sequence      182: [ 1 19 12]\n",
      "Predicted Sequence 182: [ 1 19 12]\n",
      "\n",
      "True Sequence      183: [15 18]\n",
      "Predicted Sequence 183: [19 18]\n",
      "\n",
      "True Sequence      184: [15  6]\n",
      "Predicted Sequence 184: [6 6]\n",
      "\n",
      "True Sequence      185: [9 6]\n",
      "Predicted Sequence 185: [9 3]\n",
      "\n",
      "True Sequence      186: [10 13 16]\n",
      "Predicted Sequence 186: [ 9  9 12]\n",
      "\n",
      "True Sequence      187: [ 1 19 12]\n",
      "Predicted Sequence 187: [ 1 19 12]\n",
      "\n",
      "True Sequence      188: [5 4]\n",
      "Predicted Sequence 188: [18 11  1]\n",
      "\n",
      "True Sequence      189: [20 18  9  1 12]\n",
      "Predicted Sequence 189: [20  1  1  1 11]\n",
      "\n",
      "True Sequence      190: [18  1 12 12 25]\n",
      "Predicted Sequence 190: [ 2 21 12  9  9]\n",
      "\n",
      "True Sequence      191: [20 15]\n",
      "Predicted Sequence 191: [20 15]\n",
      "\n",
      "True Sequence      192: [ 3 15 14 20  5 14 20]\n",
      "Predicted Sequence 192: [22 15  0  0  5  0  0  9]\n",
      "\n",
      "True Sequence      193: [16 18 15]\n",
      "Predicted Sequence 193: [ 3 15  5 23]\n",
      "\n",
      "True Sequence      194: [ 4 23  9  6]\n",
      "Predicted Sequence 194: [ 4 23  6  6]\n",
      "\n",
      "True Sequence      195: [16  1 25]\n",
      "Predicted Sequence 195: [ 9 25]\n",
      "\n",
      "True Sequence      196: [ 9 14 19 13  5 14 20]\n",
      "Predicted Sequence 196: [ 9 14 19 20 21 18 20  8]\n",
      "\n",
      "True Sequence      197: [ 3  4 15]\n",
      "Predicted Sequence 197: [11  1 15]\n",
      "\n",
      "True Sequence      198: [ 4 22 20 22]\n",
      "Predicted Sequence 198: [22 22 20 22]\n",
      "\n",
      "True Sequence      199: [ 1  4  4  9  3 20]\n",
      "Predicted Sequence 199: [ 9 20 15 15 15 11]\n",
      "\n",
      "True Sequence      200: [12  9 14  7 15]\n",
      "Predicted Sequence 200: [19 15  3 20  5 20]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparing the decoder input for prediction by shifting the y_test sequences\n",
    "decoder_input_test = np.zeros_like(y_test)\n",
    "decoder_input_test[:, 1:, :] = y_test[:, :-1, :]\n",
    "\n",
    "# Predict the test set sequences\n",
    "predicted_sequences = model.predict([X_test, decoder_input_test])\n",
    "\n",
    "# Convert predictions to label sequences\n",
    "predicted_labels = np.argmax(predicted_sequences, axis=-1)\n",
    "\n",
    "# Function to trim sequences by removing trailing zeros\n",
    "def trim_sequences(sequences, pad_token=0):\n",
    "    trimmed_sequences = []\n",
    "    for seq in sequences:\n",
    "        last_valid_index = 0\n",
    "        for idx, token in enumerate(seq):\n",
    "            if token != pad_token:\n",
    "                last_valid_index = idx\n",
    "        trimmed_seq = seq[:last_valid_index+1]\n",
    "        trimmed_sequences.append(trimmed_seq)\n",
    "    return trimmed_sequences\n",
    "\n",
    "# Trim the predicted and true sequences for cleaner comparison\n",
    "predicted_labels_trimmed = trim_sequences(predicted_labels)\n",
    "y_test_trimmed = trim_sequences(y_test.argmax(axis=-1))\n",
    "\n",
    "# Print out true and predicted sequences for comparison\n",
    "num_sequences_to_print = 200\n",
    "for i in range(num_sequences_to_print):\n",
    "    true_seq = y_test_trimmed[i]\n",
    "    pred_seq = predicted_labels_trimmed[i]\n",
    "    \n",
    "    print(f\"True Sequence      {i+1}: {true_seq}\")\n",
    "    print(f\"Predicted Sequence {i+1}: {pred_seq}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0789fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_test = load_model(r\"C:\\Users\\emrey\\Desktop\\Centennial\\FOURTH SEMESTER\\Software Development\\Jones Model 2D\\model_sign_2d_dim42.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62f98d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = df['padded_normalized_landmarks_42'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90d7d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_test = np.zeros_like(y_test)\n",
    "decoder_input_test[:, 1:, :] = y_test[:, :-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87f435d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1238, 125, 42)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1238, 17, 27)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_test.shape,\n",
    "decoder_input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d01fa20",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5035, 5005]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m flat_true_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(y_test_trimmed))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Compute the confusion matrix\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(flat_true_labels, flat_predicted_labels)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Assuming you have a LabelEncoder instance with the classes already fitted\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# If your labels are numbers from 0 to 26, you can create the tick labels directly\u001b[39;00m\n\u001b[0;32m     19\u001b[0m tick_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m27\u001b[39m)]  \u001b[38;5;66;03m# Adjust this range if you have a different number of classes\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[0;32m    233\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    234\u001b[0m ):\n\u001b[0;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     87\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5035, 5005]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming you have the following:\n",
    "# predicted_labels_trimmed: The list of trimmed predicted sequences\n",
    "# y_test_trimmed: The list of trimmed true sequences\n",
    "\n",
    "# Flatten the lists of sequences to create a 1D array of labels\n",
    "flat_predicted_labels = list(itertools.chain.from_iterable(predicted_labels_trimmed))\n",
    "flat_true_labels = list(itertools.chain.from_iterable(y_test_trimmed))\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(flat_true_labels, flat_predicted_labels)\n",
    "\n",
    "# Assuming you have a LabelEncoder instance with the classes already fitted\n",
    "# If your labels are numbers from 0 to 26, you can create the tick labels directly\n",
    "tick_labels = [str(i) for i in range(27)]  # Adjust this range if you have a different number of classes\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=tick_labels, yticklabels=tick_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005d4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "936cab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test: (1238, 125, 21, 3)\n",
      "Type of X_test: float64\n",
      "Shape of y_test: (1238, 17, 27)\n",
      "Type of y_test: float64\n",
      "Shape of decoder_input_test (after shifting): (1238, 17, 27)\n",
      "Model's expected input shapes: [(None, 125, 21, 3), (None, None, 27)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
      "Shape of single predicted sequence: (1, 17, 27)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Type of X_test: {X_test.dtype}\")\n",
    "\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n",
    "print(f\"Type of y_test: {y_test.dtype}\")\n",
    "\n",
    "# Assuming you've already executed:\n",
    "# decoder_input_test = np.zeros_like(y_test)\n",
    "# decoder_input_test[:, 1:, :] = y_test[:, :-1, :]\n",
    "\n",
    "print(f\"Shape of decoder_input_test (after shifting): {decoder_input_test.shape}\")\n",
    "\n",
    "# Assuming your model is named 'model'\n",
    "model_input_shapes = [model_input.shape for model_input in model.input]\n",
    "print(f\"Model's expected input shapes: {model_input_shapes}\")\n",
    "\n",
    "# Now, manually compare these shapes with the shapes of X_test and decoder_input_test you printed earlier.\n",
    "\n",
    "# Selecting a single sample from X_test and decoder_input_test\n",
    "single_X_test = np.expand_dims(X_test[0], axis=0)\n",
    "single_decoder_input_test = np.expand_dims(decoder_input_test[0], axis=0)\n",
    "\n",
    "# Making a prediction with the single sample\n",
    "single_predicted_sequence = model.predict([single_X_test, single_decoder_input_test])\n",
    "\n",
    "# Checking the shape of the predicted sequence\n",
    "print(f\"Shape of single predicted sequence: {single_predicted_sequence.shape}\")\n",
    "\n",
    "# Optionally, if you know the expected shape of the output, compare it here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
